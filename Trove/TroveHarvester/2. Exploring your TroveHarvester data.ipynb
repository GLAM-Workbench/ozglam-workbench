{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring your TroveHarvester data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd # makes manipulating the data easier\n",
    "import plotly.offline as py # for charts\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "py.init_notebook_mode() # initialise plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_harvest():\n",
    "    '''\n",
    "    Get the timestamp of the most recent harvest.\n",
    "    '''\n",
    "    harvests = sorted(os.listdir('data'))\n",
    "    return harvests[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_harvest_data(timestamp=None):\n",
    "    '''\n",
    "    Open the results of the specified harvest (most recent by default).\n",
    "    \n",
    "    Returns a DataFrame.\n",
    "    '''\n",
    "    if not timestamp:\n",
    "        timestamp = get_latest_harvest()\n",
    "    print(timestamp)\n",
    "    df = pd.read_csv(os.path.join('data', timestamp, 'results.csv'))\n",
    "    return df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = open_harvest_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's have a look!\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get the most common newspapers\n",
    "newspaper_counts = df['newspaper_title'].value_counts()\n",
    "top_newspapers = newspaper_counts[:20]\n",
    "top_newspapers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Chart the most common newspapers\n",
    "trace = go.Bar (\n",
    "            x=top_newspapers.index.values,\n",
    "            y=top_newspapers.values\n",
    "        )\n",
    "layout = go.Layout (\n",
    "            margin=go.Margin(\n",
    "                l=0,\n",
    "                r=100,\n",
    "                b=150,\n",
    "                t=50,\n",
    "                pad=4\n",
    "            ),\n",
    "            title='Most common newspapers'\n",
    "        )\n",
    "plot_data = [trace]\n",
    "fig = go.Figure(data=plot_data, layout=layout)\n",
    "py.iplot(fig, filename='top-newspapers')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show when the articles were published"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the date distribition of articles\n",
    "date_counts= df['date'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the date distribution\n",
    "trace = go.Bar (\n",
    "            x=date_counts.index.values,\n",
    "            y=date_counts.values\n",
    "        )\n",
    "layout = go.Layout(\n",
    "    yaxis=dict(\n",
    "        rangemode='tozero',\n",
    "        title='Number of articles'\n",
    "    ),\n",
    "    xaxis=dict(\n",
    "        title='Date'\n",
    "    )\n",
    ")\n",
    "plot_data = [trace]\n",
    "fig = go.Figure(data=plot_data, layout=layout)\n",
    "py.iplot(fig, filename='number-by-date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the longest article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Which is the longest article(s)?\n",
    "df[df['words'] == df['words'].max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a simple word cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the articles titles and turn them into a single string\n",
    "title_text = a = df['title'].str.lower().str.cat(sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "# Generate a word cloud image\n",
    "wordcloud = WordCloud(width=1200, height=800).generate(title_text)\n",
    "\n",
    "# Display the generated image:\n",
    "# the matplotlib way:\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "from operator import itemgetter\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "blob = TextBlob(title_text)\n",
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "word_counts = [[word, count] for word, count in blob.lower().word_counts.items() if word not in stopwords]\n",
    "word_counts = sorted(word_counts, key=itemgetter(1), reverse=True)[:25]\n",
    "pd.DataFrame(word_counts).style.format({1: '{:,}'}).bar(subset=[1], color='#d65f5f').set_properties(subset=[1], **{'width': '300px'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping newspaper locations\n",
    "\n",
    "This makes use of a spreadsheet file that maps Trove newspaper titles to locations. Once we've loaded the spreadsheet we can use it to locate all of the harvested articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Url of the Trove places spreadshseet\n",
    "trove_places = 'https://docs.google.com/spreadsheets/d/1rURriHBSf3MocI8wsdl1114t0YeyU0BVSXWeg232MZs/gviz/tq?tqx=out:csv&sheet=198244298'\n",
    "\n",
    "# Open the CSV file with Pandas\n",
    "place_df = pd.read_csv(trove_places)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're going to map the locations using ipyleaflet, a Python implementation of the popular Leaflet javascript library.\n",
    "# Let's import what we need.\n",
    "from ipyleaflet import Map, Marker, MarkerCluster\n",
    "\n",
    "# Create the map\n",
    "m = Map(center=(-28, 140), zoom=4)\n",
    "\n",
    "# Loop through the results creating a marker for each article\n",
    "markers = []\n",
    "for row in df.itertuples(index=False):\n",
    "    try:\n",
    "        # Look up the newspaper identifier in the locations spreadsheet\n",
    "        location = place_df.loc[place_df['title_id'] == row.newspaper_id].iloc[0]\n",
    "    except IndexError:\n",
    "        # There are Government Gzettes\n",
    "        print('Not found: {}'.format(row.newspaper_id))\n",
    "    marker = Marker(location=(float(location['latitude']), float(location['longitude'])))\n",
    "    markers.append(marker)\n",
    "\n",
    "marker_cluster = MarkerCluster(\n",
    "    markers=markers\n",
    ")\n",
    "\n",
    "m.add_layer(marker_cluster);\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore article texts in Voyant Tools\n",
    "\n",
    "First we need to zip up all the little text files for easy transport."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "def zip_harvest_texts(timestamp=None):\n",
    "    if not timestamp:\n",
    "        timestamp = get_latest_harvest()\n",
    "    data_dir = os.path.join('data', timestamp)\n",
    "    texts_dir = os.path.join(data_dir, 'text')\n",
    "    with zipfile.ZipFile(os.path.join(data_dir, '{}-texts.zip'.format(timestamp)), 'w', zipfile.ZIP_DEFLATED) as zip_file:\n",
    "        text_files = [t for t in os.listdir(texts_dir) if t[-4:] == '.txt']\n",
    "        for text_file in text_files:   \n",
    "            zip_file.write(os.path.join(texts_dir, text_file), text_file)\n",
    "\n",
    "zip_harvest_texts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save titles to a text file\n",
    "timestamp = get_latest_harvest()\n",
    "df['title'].to_csv(os.path.join('data', timestamp, 'titles.txt'), index=False, index_label=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
